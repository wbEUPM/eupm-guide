---
title: "Multivariate Fay Herriot Modelling"
author: "Ifeanyi Edochie"
date: "2025-04-16"
output: 
  html_document:
    toc: true
    toc_depth: 5  
    toc_float: true  

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

if (sum(installed.packages()[,1] %in% "pacman") != 1){
  install.packages("pacman")
}

pacman::p_load(sae, msae, tidyverse, ggplot2)

```

# Multivariate Fay–Herriot Modelling

## Stable FH estimators over T time periods
This section describes procedures that yield stable small area estimators for each of $D$ areas over $T$ subsequent time instants. 

MFH estimation procedure for T time instants:
  - Step 1: Compute the selected direct area estimators for each area $d = 1, . . . , D$ for each time $t = 1, . . . , T,$ and estimators of their corresponding sampling variances and covariances.

  - Step 2: Select the area-level auxiliary variables for each time instant in the MFH model. A simple approach is to perform a model selection procedure in a linear regression model without the area effects for each time instant t = 1, . . . , T .

  - Step 3: Fit MFH3 model and test whether the area-time effects $(u_{d1}, . . . , u_{dT})$ are homoscedastic or not. If we reject the homoscedasticity of variances, consider MFH3 model. Otherwise, consider MFH2 model.

  - Step 4: Check the selected model assumptions, including linearity, normality of predicted area effects and standardized model residuals, and the presence of outlying areas.

  - Step 5: In case of clear systematic model departures, the model should be changed. In case of isolated departures because of outlying areas, either do not obtain the MFH estimate for those areas or change some aspect of the model or the data. Then, go to Step 2.

  - Step 6: If model assumptions hold, using the above direct estimates and estimated sampling variances and covariances, and the selected auxiliary variables, compute MFH estimators for, $d = 1, . . . , D$ and $t = 1, . . . , T$ and their corresponding estimated MSEs.

The functions `eblupMFH2()` and `eblupMFH3()` from the R package msae (Permatasari and Ubaidillah, 2022) compute the EBLUPs and their MSE estimates under the MFH models 2 and 3, respectively. The calls to these functions are:
$eblupMFH2(formula, vardir, MAXITER = 100, PRECISION = 1e-04, data)$ or $eblupMFH3(formula, vardir, MAXITER = 100, PRECISION = 1e-04, data)$.

The arguments of these two functions are the same, differing only in the outputs. They require specifying a list with T R formula objects, one for each time instant, separated by commas. In each of these regression formulas (one for each time instant), we place the vector of direct estimates on the left-hand side and the area-level independent variables on the right-hand side, separated by “+”. As usual, by default an intercept is automatically included in each regression formula.

As in the case of the `eblupFH()` function, they also require specifying the estimated sampling variances and covariances of the direct estimators for each area and time in the argument vardir. The user can also modify the maximum number of iterations, MAXITER, which is set by default to 100, and the convergence tolerance criteria, PRECISION, of the Fisher-scoring algorithm, which is set to 1e-4. The final argument, data, can be optionally specified to indicate a data object that includes the variables found in formula and vardir as its columns. Similar to the eblupFH() function, these functions do not accept NA values, and they will not return estimates for areas with zero sample sizes. Consequently, such areas should be excluded from the dataset.

Both functions return a list containing the following objects: eblup, a vector of EBLUPs for the areas; MSE, a data frame with the estimated mean squared errors of the EBLUPs; randomEffect, a data frame containing the predicted area-time effects; Rmatrix, a diagonal matrix with the sampling errors; and fit, a list with additional information from the model fitting. In the fit list, we can find the fitting method used (method); a logical value indicating the convergence of the Fisher scoring algorithm (convergence); the number of iterations performed by the Fisher scoring algorithm (iterations); a data frame containing the estimated regression coefficients in the first column, their standard errors in the second, the t statistics in the third, and the p-values of the significance of each coefficient in the last column (estcoef); a data frame with the estimated random effects variance (refvar); a data frame with the estimated autocorrelation coefficient ρ of the random effects; and the estimated Fisher information matrix (informationFisher).

The function `eblupMFH3()` additionally includes in the fit list, a contrast to test the homogeneity of random effects variance, called `refvarTest`. This test helps the user to choose between the heteroscedastic Model 3 or the homoscedastic Model 2, for a particular data set.

Example 1 below illustrates the calculation of MFH estimators of area poverty rates for T time instants, using the functions `eblupMFH2()` and `eblupMFH3()` of the R package msae (Permatasari and Ubaidillah, 2022).

### Example 1 (MFH estimators of poverty rates for T time periods, in R) 
In this example, we use the data set datasae3 from the R package msae (Permatasari and Ubaidillah, 2022). This data set contains simulated data generated under a FH model with heteroscedastic AR(1) area-time effects. There are two auxiliary variables, X1 and X2. Direct estimates for time instants 1,2 and 3 are given in Y1, Y2, and Y3, respectively. The elements of the variance-covariance matrix of the sampling errors are given in v1, v2, v3, v12, v13 and v23. 

We first load the package and the data set:

```{r load_data, message = FALSE, warning = FALSE}
library(msae)

data(datasae3)

glimpse(datasae3)

```

Step 1: The direct area estimators and their sample variances are already given in the dataset.
Step 2: We should select the auxiliary variables at each time point. This example is only for illustration of application of the R function, and hence we use all the available variables, but we should emphasize the importance of this variable selection process in real-world applications.
Step 3: In order to choose between the two alternative MFH models with heteroscedastic or homoscedastic area-time effects, we fit the heteroscedastic Model 3, and then check for the equality of the variances over the three time points. Hence, we use the function `eblupMFH3()` to fit the model:

```{r run_mfh3, message = FALSE, warning = FALSE}


Fo <- list(f1 = Y1 ~ X1 + X2,
           f2 = Y2 ~ X1 + X2, 
           f3 = Y3 ~ X1 + X2)

vardir <- c("v1", "v2", "v3", "v12", "v13", "v23") 

m3 <- eblupMFH3(Fo, vardir, data = datasae3)

```

Next we check the equality of the random effect variances. For this, we use the results of a hypothesis test included in the output of the function eblupMFH3:
$m3$fit$refvarTest$.

```{r}

m3$fit$refvarTest


```


This test tests the null hypothesis that the variances $σ^2$ at each pair of instants t and s are equal against the alternative that they are not. In this case, at significance level of 0.05, we reject the equality of variances between $t = 3$ and $t = 1$, as well as between $t = 3$ and $t = 2$. Note that this is a multiple test, and hence it is advisable to adjust the significance level. In this case, the tests clearly indicate heteroscedasticity, and we proceed with Model 3. If these tests supported equality of variances, then we would use instead the function eblupMFH2 for estimation.

Step 4: We now verify the assumptions of the MFH3 model. This includes assessing linearity, the normality of the predicted area effects and standardized residuals, as well as checking for the presence of outlying areas. We first check the linearity assumption. This can be addressed by examining the scatter plot of residuals against predicted values (EBLUPs). The plot is generated for each of the $T = 3$ time periods.

```{r figure1, message = FALSE, warning = FALSE}

resids_3 <- cbind(datasae3$Y1 - m3$eblup$Y1,
                  datasae3$Y2 - m3$eblup$Y2,
                  datasae3$Y3 - m3$eblup$Y3)

layout(matrix(1:3, nrow = 1, byrow = TRUE))

plot(m3$eblup$Y1, resids_3[,1], pch = 19, xlab = "EBLUPs t = 1", ylab = "Residuals t = 1")
plot(m3$eblup$Y2, resids_3[,2], pch = 19, xlab = "EBLUPs t = 2", ylab = "Residuals t = 2")
plot(m3$eblup$Y1, resids_3[,3], pch = 19, xlab = "EBLUPs t = 3", ylab = "Residuals t = 3")

```

These three plots do not provide evidences against the linearity assumption if we look at it by visual inspection. More formally, we can extract the fitted values (EBLUPs), regress the direct estimates on the model-predicted values and their powers, to see if there is actually explanatory power. 

```{r}

fits_3 <- m3$eblup  # EBLUPs (predicted values)

# Run regression of residuals on fitted values for each time period
lm_resid_fit_t1 <- lm(resids_3[,1] ~ fits_3$Y1)
lm_resid_fit_t2 <- lm(resids_3[,2] ~ fits_3$Y2)
lm_resid_fit_t3 <- lm(resids_3[,3] ~ fits_3$Y3)

# View summaries
summary(lm_resid_fit_t1)
summary(lm_resid_fit_t2)
summary(lm_resid_fit_t3)

```

We now evaluate the normality assumption of residuals for the three periods using the Shapiro-Wilks normality tests.
 
```{r shapirowilks, message = FALSE, warning = FALSE}

# layout(matrix(1:2,nrow = 1, byrow = TRUE))
# hist(resids_3[,1], probability=TRUE, main="",xlab="Residuals t=1", ylim=c(0,3.7))
# mean_est <- mean(resids_3[,1]) 
# sd_est <- sd(resids_3[,1])
# curve(dnorm(x, mean=mean_est, sd=sd_est), add=TRUE, col="red", lwd=2) 
# qqnorm(resids_3[,1], main="")
# qqline(resids_3[,1], col="red") 
# shapiro.test(resids_3[,1])

resid_dt <- data.frame(
  t1 = datasae3$Y1 - m3$eblup$Y1,
  t2 = datasae3$Y2 - m3$eblup$Y2,
  t3 = datasae3$Y3 - m3$eblup$Y3
)

shapiro_t1 <- shapiro.test(resid_dt$t1)

shapiro_t2 <- shapiro.test(resid_dt$t2)

shapiro_t3 <- shapiro.test(resid_dt$t3)

summary_dt <- 
data.frame(
  Time = c("t1", "t2", "t3"),
  W = c(shapiro_t1$statistic, shapiro_t2$statistic, shapiro_t3$statistic),
  p_value = c(shapiro_t1$p.value, shapiro_t2$p.value, shapiro_t3$p.value)
)

```
The results seem to suggest normal distributions for each of the time period residuals. 


```{r normalityplots, message = FALSE, warning = FALSE}

summary_dt <- 
  summary_dt %>%
  mutate(label = paste0("W = ", round(W, 3), "\n", "p = ", signif(p_value, 3)))

resid_dt %>%
  pivot_longer(cols = everything(), 
               names_to = "Time", 
               values_to = "Residual") %>%
  ggplot(aes(x = Residual)) + 
  geom_histogram(bins = 10, fill = "steelblue", color = "white") + 
  geom_text(data = summary_dt, aes(x = -Inf, y = Inf, label = label),
            hjust = -0.1, vjust = 1.2, inherit.aes = FALSE, size = 3.5) +
  facet_wrap(~Time, scales = "free") + 
  theme_minimal() + 
  labs(title = "Residual Histograms by Time Period")

resid_dt %>%
  pivot_longer(cols = everything(), 
               names_to = "Time", 
               values_to = "Residual") %>%
  ggplot(aes(sample = Residual)) +
  stat_qq() +
  stat_qq_line() +
  facet_wrap(~Time, scales = "free") +
  theme_minimal() +
  labs(title = "QQ Plots of Residuals by Time Period")

```


In this case, the above histograms and Q-Q normal plots, as well as the Shapiro-Wilk tests, indicate nothing against the normality assumption of residuals. We next evaluate the normality of the random effects. Luckily, the function `eblupMFH3()` provides the random effects in its output, for the three time periods:

```{r figure5, message = FALSE, warning = FALSE}

# Convert to dataframe (if not already)
raneff_dt <- as.data.frame(m3$randomEffect)

# Run Shapiro-Wilk tests
shapiro_u1 <- shapiro.test(raneff_dt$Y1)
shapiro_u2 <- shapiro.test(raneff_dt$Y2)
shapiro_u3 <- shapiro.test(raneff_dt$Y3)

# Combine into summary table
summary_dt <- 
data.frame(
  Time = c("Y1", "Y2", "Y3"),
  W = c(shapiro_u1$statistic, shapiro_u2$statistic, shapiro_u3$statistic),
  p_value = c(shapiro_u1$p.value, shapiro_u2$p.value, shapiro_u3$p.value)
)

summary_dt

```

Now, lets plot it! 
```{r, message = FALSE, warning = FALSE}

summary_dt <- 
  summary_dt %>%
  mutate(label = paste0("W = ", round(W, 3), "\n", "p = ", signif(p_value, 3)))

raneff_dt %>% 
  pivot_longer(cols = everything(), names_to = "Time", values_to = "RandEff") %>%
  ggplot(aes(x = RandEff)) + 
    geom_histogram(bins = 10, fill = "darkorange", color = "white") + 
    facet_wrap(~Time, scales = "free") +
    geom_text(data = summary_dt, aes(x = -Inf, y = Inf, label = label),
            hjust = -0.1, vjust = 1.2, inherit.aes = FALSE, size = 3.5) +
    theme_minimal() + 
    labs(title = "Histogram of Random Effects")
  

```

Again, histograms and Q-Q normal plots show no evidences of departure from normality, while the Shapiro-Wilk test also supports normality for all time periods at the usual significance level of 0.05, except for t = 2, which is supported at 0.01 level.

Step 5: Since no indications are found against the MFH3 model assumptions, we proceed to obtain the small area estimates, as well as their estimated MSEs. These are already been generated at output of the function together with the model fit, and can be printed as follows (showing on the first 6 observations):

```{r}

head(m3$eblup)

head(m3$MSE)

```

We next illustrate the use of the function eblupMFH2, which should be used in the case of homoscedastic area-time effects over time. For this, we employ datasae2 from the R package msae (Permatasari and Ubaidillah, 2022). In this new data set, again X1 and X2 are the auxiliary variables, and Y1, Y2, and Y3 are the direct estimates at times 1, 2, and 3, respectively. The elements of the variance-covariance matrix of the sampling errors are provided in the variables v1, v2, v3, v12, v13, and v23. Again, we first load the package and the data set:

```{r load_data2, message = FALSE, warning = FALSE}

library(msae) 
data(datasae2)

```

We now fit model MFH2 and check the model assumptions:

```{r run_mfh2, message = FALSE, warning = FALSE}

Fo <- list(f1 = Y1 ~ X1 + X2,
           f2 = Y2 ~ X1 + X2, 
           f3 = Y3 ~ X1 + X2)

vardir <- c("v1", "v2", "v3", "v12", "v13", "v23")

m2 <- eblupMFH2(Fo, vardir, data = datasae2)

m2$eblup

m2$MSE

```

##	Spatio-temporal FH estimators over T time periods
This section describes an extension of the FH model by Marhuenda et al. (2013), which incorporates spatial correlation between neighboring areas and temporal correlation over T time instants, leading to more stable small area estimates over time.

STFH estimation procedure for T time instants:
Step 1 Compute the selected direct area estimators for each area, $d = 1, . . . , D$ and for each time $t = 1, . . . , T$ and estimators of their corresponding sampling variances.

Step 2 Select the area-level auxiliary variables for each time instant in the STFH model. A simple approach is to perform a model selection procedure in a linear regression model without the area effects for each time instant $t = 1, . . . , T$.

Step 3 Fit the STFH model and check the model assumptions, including linearity, normality of predicted area effects and standardized model residuals, and the presence of outlying areas, for each time instant $T$.

Step 4 In case of clear systematic model departures, the model should be changed. In case of isolated departures because of outlying areas, either do not obtain the STFH estimate for those areas or change some aspect of the model or the data. Then, go to Step 2.

Step 5 If model assumptions hold, using the above direct estimates, their estimated sampling variances, and the selected auxiliary variables, compute STFH estimators for each area d = 1, . . . , D and each time $t = 1, . . . , T$ and their corresponding estimated MSEs.

EBLUPs for all areas and time instants, and parametric bootstrap MSE estimates can be obtained calling functions `eblupSTFH()` and `pbmseSTFH()` respectively. 
The calls to these functions are:
$eblupSTFH(formula, D, T, vardir, proxmat, model = "ST", MAXITER =100, PRECISION = 0.0001, data)$
$pbmseSTFH(formula, D, T, vardir, proxmat, B = 100, model = "ST", MAXITER = 100, PRECISION = 0.0001, data)$
 
Some of the arguments are exactly the same as in the functions for FH model described in Section 4. Among the additional arguments, we have the number of areas D and the number of time periods T for each area. We remark that these functions may be used only when data are available for all the D domains at all T time periods. Moreover, data in formula and vardir must be sorted in ascending order by time instant, for each domain. Note that a single formula is specified in this function, unlike in the functions for the MFH modes of Section 5. The argument model can be chosen between the default value ST (AR(1) time-effects within each domain) or value S (with uncorrelated time effects within each domain). The rwo-standardized proximity matrix, W, must be also given as input in proxmat. The elements of this matrix are in [0,1], zeros on the diagonal and rows adding up to 1, as described above.

The function `pbmseSTFH()` providing bootstrap MSE estimates requires additionally to specify the number of bootstrap replicates B. A number of bootstrap replicates B ≥ 400 is advisable to achieve stable MSE estimates. By default, the argument B is set to 100 to save computing time. To obtain the same MSE estimates every time the function `pbmseSTFH()` is run, the seed for random number generation should be fixed previously using `set.seed()`. 

Example 2 illustrates the calculation of STFH estimators of area poverty rates for T time instants, using the above functions.

### Example 2 (Spatio-temporal FH estimators of poverty rates) 
In this example, we use the data set spacetime included in the R package sae, which contains synthetic area level data for $T = 3$ time points, for each of D = 11 areas. The data set contains the following variables: Area, area code, Time, time point, X1 and X2, the auxiliary variables for each area and time instant, Y2, direct estimates for each area and time instant, and Var, sampling variances of the direct estimators. We calculate EBLUPs of the means for each area at each time, based on the STFH model with proximity matrix given in the data set spacetimeprox. We also obtain the corresponding MSE estimates by parametric bootstrap. The steps of the STFH procedure described above should be followed but, in this example, we only illustrate the calculation of the small area estimators and their estimated MSEs. 

We first load the two data sets and obtain the number of areas and of time instants. Then, we apply the function pbmseSTFH() that delivers both, the STFH estimates and their estimated MSEs:

```{r sptdata1, message = FALSE, warning = FALSE}
data("spacetime") 
data("spacetimeprox")

glimpse(spacetime)

```


```{r sptdata2, message = FALSE, warning = FALSE}

glimpse(spacetimeprox)

```


```{r run_STFH, message = FALSE, warning = FALSE}

area_count <- nrow(spacetimeprox)	# number of areas

time_count <- length(unique(spacetime$Time))	# number of time periods set.seed(123)

stfh_obj <- pbmseSTFH(formula = Y ~ X1 + X2, 
                      D = area_count, 
                      T = time_count, 
                      vardir = Var, 
                      proxmat = spacetimeprox, 
                      data = spacetime)

```

The bootstrap procedure for MSE estimation displays the iteration number for each step, as follows:
Bootstrap procedure with B = 100 iterations starts. 
Once we have obtained the STFH estimators, we compute their CVs, and the same is done for the direct estimators. We print the results for the last time instant $(T = 3)$:
 
```{r cv_STFH, message = FALSE, warning = FALSE}
stfh_cv <- 100 * sqrt(stfh_obj$mse) / stfh_obj$est$eblup 

direct_cv <- 100 * sqrt(spacetime$Var) / spacetime$Y

results_dt <- data.frame(area = spacetime$Area, 
                         time = spacetime$Time, 
                         direct = spacetime$Y, 
                         eblup_stfh = stfh_obj$est$eblup, 
                         direct_cv = sqrt(spacetime$Var) / spacetime$Y, 
                         stfh_cv = sqrt(stfh_obj$mse) / stfh_obj$est$eblup)


```

Next we plot the STFH and the direct estimates together for comparison. Additionally, we plot their corresponding CVs. The following R code generates both plots:

```{r stfhvsdirectpov, message = FALSE, warning = FALSE}

### comparing the stfh and direct estimates
# Reshape to long format
results_dt %>%
  pivot_longer(cols = c("direct", "eblup_stfh"),
               names_to = "method",
               values_to = "estimate") %>%
  ggplot(aes(x = factor(area), 
             y = estimate, 
             color = method, 
             group = method)) +
  geom_line(size = 1) +
  geom_point() +
  facet_wrap(~time, ncol = 1) +
  labs(
    x = "Area",
    y = "Estimate",
    title = "Direct vs EBLUP Estimates by Area and Time",
    color = "Method"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12),
    axis.text.x = element_text(angle = 90, hjust = 1)
  )



```

We also compare the coefficient of variation on the direct and EBLUP spatio temporal FH model estimates. See the code and results below: 

```{r stfhvsdirectcv, message = FALSE, warning = FALSE}

results_dt %>%
  pivot_longer(cols = c("direct_cv", "stfh_cv"),
               names_to = "method",
               values_to = "estimate") %>%
  ggplot(aes(x = factor(area), 
             y = estimate, 
             color = method, 
             group = method)) +
  geom_line(size = 1) +
  geom_point() +
  facet_wrap(~time, ncol = 1) +
  labs(
    x = "Area",
    y = "CV",
    title = "Direct vs EBLUP CVs by Area and Time",
    color = "Method"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12),
    axis.text.x = element_text(angle = 90, hjust = 1)
  )


```

### Comparing the Spatio-Temporal FH, Univariate FH and Direct Estimation Methods
We compare the EBLUP spatio temporal FH estimates with the univariate FH estimates just to see how different our results would be if we treated each year as uncorrelated with other years. 

```{r stfhvsfhvsdirectest, message = FALSE, warning = FALSE}

## estimate the univariate FH models for each time period
ufh_time1 <- mseFH(Y ~ X1 + X2, vardir = Var, data = spacetime[spacetime$Time == 1,])
ufh_time2 <- mseFH(Y ~ X1 + X2, vardir = Var, data = spacetime[spacetime$Time == 2,])
ufh_time3 <- mseFH(Y ~ X1 + X2, vardir = Var, data = spacetime[spacetime$Time == 3,])

## create the table of fh estimates and cvs
fh_dt <- 
rbind(data.frame(area = spacetime$Area[spacetime$Time == 1], 
                 time = spacetime$Time[spacetime$Time == 1], 
                 eblup_fh = ufh_time2$est$eblup, 
                 fh_cv = sqrt(ufh_time2$mse) / ufh_time2$est$eblup),
      data.frame(area = spacetime$Area[spacetime$Time == 2], 
                 time = spacetime$Time[spacetime$Time == 2], 
                 eblup_fh = ufh_time2$est$eblup, 
                 fh_cv = sqrt(ufh_time2$mse) / ufh_time2$est$eblup),
      data.frame(area = spacetime$Area[spacetime$Time == 3], 
                 time = spacetime$Time[spacetime$Time == 3], 
                 eblup_fh = ufh_time3$est$eblup, 
                 fh_cv = sqrt(ufh_time3$mse) / ufh_time3$est$eblup))



### now lets show that stfh estimates are more stable than FH and direct over time
plot_dt <- 
  rbind(results_dt %>%
          pivot_longer(cols = c("direct", "eblup_stfh"),
                       names_to = "method",
                       values_to = "estimate") %>%
          dplyr::select(area, time, estimate, method),
        fh_dt %>% 
          pivot_longer(cols = c("eblup_fh"),
                       names_to = "method",
                       values_to = "estimate") %>%
          dplyr::select(area, time, estimate, method))

plot_dt %>%
  ggplot(aes(x = as.factor(time), 
             y = estimate, 
             color = method, 
             group = method)) +
  geom_line(size = 1) +
  geom_point() +
  facet_wrap(~area, ncol = 3, scales = "free_y") +
  labs(
    x = "Time",
    y = "Estimates",
    title = "Comparing Stability of Spatio-Temporal FH vs FH vs Direct Estimates",
    color = "Method"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12),
    axis.text.x = element_text(angle = 90, hjust = 1)
  )


```

The results suggest that the STFH estimates are less volatile than the FH which is in turn smoother than the direct estimates. 

The Spatio-Temporal models will likely also provide more efficient error rates relative to the univariate FH which by default improves on the direct estimates. See the results below: 


```{r stfhvsfhvsdirectcv, message = FALSE, warning = FALSE}

### now lets show that stfh estimates are more stable than FH and direct over time
plot_dt <- 
  rbind(results_dt %>%
          pivot_longer(cols = c("direct_cv", "stfh_cv"),
                       names_to = "method",
                       values_to = "estimate") %>%
          dplyr::select(area, time, estimate, method),
        fh_dt %>% 
          pivot_longer(cols = c("fh_cv"),
                       names_to = "method",
                       values_to = "estimate") %>%
          dplyr::select(area, time, estimate, method))

plot_dt %>%
  ggplot(aes(x = as.factor(time), 
             y = estimate, 
             color = method, 
             group = method)) +
  geom_line(size = 1) +
  geom_point() +
  facet_wrap(~area, ncol = 3, scales = "free_y") +
  labs(
    x = "Time",
    y = "CV",
    title = "Comparing Stability of Spatio-Temporal FH vs FH vs Direct Estimates",
    color = "Method"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12),
    axis.text.x = element_text(angle = 90, hjust = 1)
  )

```




















