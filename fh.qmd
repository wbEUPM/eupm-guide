# Fay–Herriot (TODO)

## Data and variables preparation
The example code uses the Ghana data from the [summer school](https://github.com/pcorralrodas/wb_sae_training/tree/SummerU_2024.).

### Load required libraries
```{r libraries}
library(raedstata13)      # For reading .dta files
library(dplyr)      # For data manipulation
library(sae)       # For SAE modeling
library(car)        # For VIF calculation
library(ggplot2)    # For histogram and Q-Q plots
library(fastDummies) # Create dummy variables
```

### Load the dataset
```{r load_data}
data <- read.dta13("FHcensus_district.dta") 
```

### Define the variable list
```{r list_variable}
vars <- c("male", "head_age", "age", "depratio", "head_ghanaian", "ghanaian",
          "head_ethnicity1", "head_ethnicity2", "head_ethnicity3", "head_ethnicity4",
          "head_ethnicity5", "head_ethnicity6", "head_ethnicity7", "head_ethnicity8",
          "head_ethnicity9", "head_birthplace1", "head_birthplace2", "head_birthplace3",
          "head_birthplace4", "head_birthplace5", "head_birthplace6", "head_birthplace7",
          "head_birthplace8", "head_birthplace9", "head_birthplace10", "head_birthplace11",
          "head_religion1", "head_religion2", "head_religion3", "head_religion4", "christian",
          "married", "noschooling", "head_schlvl1", "head_schlvl2", "head_schlvl4", "head_schlvl5",
          "employed", "head_empstatus1", "head_empstatus2", "head_empstatus3", "head_empstatus4",
          "head_empstatus5", "head_empstatus6", "head_empstatus8", "head_empstatus9", "employee",
          "internetuse", "fixedphone", "pc", "aghouse", "conventional", "wall2", "wall3", "floor2",
          "floor3", "roof1", "roof2", "roof3", "tenure1", "tenure3", "rooms", "bedrooms", "lighting2",
          "lighting3", "lighting4", "water_drinking1", "water_drinking3", "water_drinking4",
          "water_general2", "water_general3", "fuel1", "fuel2", "fuel3", "toilet1", "toilet3",
          "toilet4", "toilet5", "solidwaste1", "solidwaste2", "solidwaste3")
```

### Normalize variables
```{r normalize_variable}
data <- data %>%
  mutate(across(all_of(vars), ~ ifelse(!is.na(.), (.-mean(.))/sd(.), NA)))
```

### Create D variable and prepare for merging
```{r normalize_variable}
data <- data %>%
  mutate(D = region * 100 + district) %>% 
  dplyr::select(-district) %>%
  rename(district = D)
```

### Merge with direct estimates
```{r merge}
direct_data <- read.dta13("direct_glss7.dta")
data <- data %>%
  left_join(direct_data, by = "district") 
```

### Create region indicators
```{r region}
data <- dummy_cols(data,select_columns = "region.x")
data <- data %>% rename_with(~str_replace(.,"region.x_",replacement = "thereg"),starts_with("region.x_")) 
hhvars <- c(vars,"thereg1","thereg2","thereg3","thereg4","thereg5","thereg6","thereg7","thereg8","thereg9")
```

### Variance smoothing
```{r variance_smoothing}
data <- data %>%
  mutate(
    log_s2 = log(dir_fgt0_var),
    logN = log(N),
    logN2 = logN^2,
    logpop = log(pop),
    logpop2 = logpop^2,
    accra = as.numeric(region.x == 3),
    share = log(N_hhsize / pop)
  )

fit <- lm(log_s2 ~ share, data = data)
summary(fit)
phi2 <- summary(fit)$sigma^2
data$xb_fh <- predict(fit, data)

data <- data %>%
  mutate(
    exp_xb_fh = exp(xb_fh),
    smoothed_var = exp_xb_fh * (sum(dir_fgt0_var, na.rm = TRUE) / sum(exp_xb_fh, na.rm = TRUE)),
    dir_fgt0_var = ifelse(((num_ea > 1 & !is.na(num_ea)) | (num_ea == 1 & zero != 0 & zero != 1)) & is.na(dir_fgt0_var),
                                   smoothed_var, dir_fgt0_var),
             dir_fgt0 = ifelse(!is.na(dir_fgt0_var), zero, dir_fgt0)
  )
```


## Fay-Herriot SAE modeling

### Model creation
```{r fh_model}
formula <- as.formula(paste("dir_fgt0 ~", paste(hhvars, collapse = "+")))
data2 <- data[,c(hhvars,"dir_fgt0", "dir_fgt0_var","region.y","district")]
data3 <- na.omit(data2)
```

### Check the perfect multicollinearity
```{r check_multicollinearity}
alias( formula, data = data3)
hhvars2 <- setdiff(hhvars, "head_birthplace8")
```

### Model creation2
```{r fh_model2}
formula <- as.formula(paste("dir_fgt0 ~", paste(hhvars2, collapse = "+")))
fh_model <- eblupFH(formula,vardir = dir_fgt0_var, data = data3, method = "FH")
```

#Iterative refinement
First, we omit the variables in the model of which the p-value is not significant.

```{r fh_model_refinement1}
for (z_threshold in seq(0.8,0.05, by = -0.05)) {
  print(z_threshold)
  #Fit Fay-Herriot model
  formula <- as.formula(paste("dir_fgt0 ~", paste(hhvars2, collapse = "+")))
  fh_model <- eblupFH(formula,vardir = dir_fgt0_var, data = data3, method = "FH")
  #Extract z-values )coefficients / standard errors)
  zvals <- abs(fh_model$fit[["estcoef"]][-1,"beta"] / fh_model$fit[["estcoef"]][-1,"std.error"])
  #Find the smallest absolute z-value
  min_zval <- min(zvals)
  #Exit loop if all z-values are above the threshol
  if(2 * pnorm(-min_zval) < z_threshold) {
  break
  }
  for (x in hhvars2) {
    print(x)
    # Fit the Fay-Herriot model with current variables
    fh_model <- eblupFH(as.formula(paste("dir_fgt0 ~", paste(hhvars2, collapse = " + "))), 
                        vardir = dir_fgt0_var, method = "FH", data = data3)
    
    # Extract p-value for the variable `x`
    p_value <- fh_model$fit[["estcoef"]][x, 4]  
    
    # Remove the variable if p-value > threshold
    if (p_value > z_threshold) {
      hhvars2 <- setdiff(hhvars2, x)  # Remove x from the list
    }
  }
  
  # Update the variable list
  hhvars2 <- hhvars2
}
```

### Final model without non-significant variables
```{r fh_model3}
formula <- as.formula(paste("dir_fgt0 ~", paste(hhvars2, collapse = "+")))
fh_model_updated <- eblupFH(formula,vardir = dir_fgt0_var, data = data3, method = "FH")
```

###  Function to remove the variables with high VIF
Next, we omit the variables with strong multicolliearity. For that, we create the function stepwise_vif.

```{r vif_function}
stepwise_vif <- function(data, predictors, weight, threshold) {
  
  # Select predictor variables 
  dir_fgt0 <- data3$dir_fgt0
  x_data <- data3[, hhvars2]
  formula <- as.formula(paste("dir_fgt0 ~", paste(hhvars2, collapse = "+")))
  # Function to calculate VIF for a set of predictors
  vif_values <- vif(lm(formula, weights = rep(1,nrow(data3)), data = x_data))
  
  # Stepwise elimination
  while (max(vif_values, na.rm = TRUE) > threshold) {
    # Find the variable with the highest VIF
    max_vif_var <- names(which.max(vif_values))
    
    # Remove that variable from the dataset
    predictors <- setdiff(predictors, max_vif_var)
    x_data <- data3[, predictors]
    
    # Recalculate VIF with the updated variable set
    formula <- as.formula(paste("dir_fgt0 ~", paste(predictors, collapse = "+")))
    vif_values <- vif(lm(formula, weights = rep(1,nrow(data3)), data = x_data))
  }
  
  return(predictors)  # Return the final set of predictors with VIF ≤ threshold
}
```

### Apply the function to remove the variables witth high multicollinearity
```{r remove_vif}
hhvars3 <- stepwise_vif(data3, hhvars2, weight = rep(1,nrow(data3)), threshold = 5)
print(hhvars3)
```

### One final removal of non-significant covariates
After omitting the variables with high multicollinearity, we check again the p-value of each variable, and omit it if it is not significant.

```{r fh_model_refinement2}
for (z_threshold in seq(0.8,0.0001, by = -0.05)) {
  print(z_threshold)
  #Fit Fay-Herriot model
  formula <- as.formula(paste("dir_fgt0 ~", paste(hhvars3, collapse = "+")))
  fh_model <- eblupFH(formula,vardir = dir_fgt0_var, data = data3, method = "REML", PRECISION = 1e-10)
  #Extract z-values )coefficients / standard errors)
  zvals <- abs(fh_model$fit[["estcoef"]][-1,"beta"] / fh_model$fit[["estcoef"]][-1,"std.error"])
  #Find the smallest absolute z-value
  min_zval <- min(zvals)
  pvalue <- 2 * pnorm(-min_zval)
  print(pvalue)
 
  if(2 * pnorm(-min_zval) > z_threshold) {
 
  for (x in hhvars3) {
    print(x)
    # Fit the Fay-Herriot model with current variables
    fh_model <- eblupFH(as.formula(paste("dir_fgt0 ~", paste(hhvars3, collapse = " + "))), 
                        vardir = dir_fgt0_var, method = "REML", data = data3, PRECISION = 1e-10)
    
    # Extract p-value for the variable `x`
    p_value <- fh_model$fit[["estcoef"]][x, 4]  
    
    # Remove the variable if p-value > threshold
    if (p_value > z_threshold) {
      hhvars3 <- setdiff(hhvars3, x)  # Remove x from the list
    }
  }
  }
  # Update the variable list
  hhvars3 <- hhvars3
}
```

### Comparison of the different FH methods
The type of FH model can be mainly three, ML, REML, and FH. We check the performance of each model, and select the one withthe lowest log likelihood. It is REML in this case.

```{r fh_model_comparison}
formula <- as.formula(paste("dir_fgt0 ~", paste(hhvars3, collapse = "+")))
fh_model_ML <- eblupFH(formula,vardir = dir_fgt0_var, data = data3, method = "ML")
fh_model_REML <- eblupFH(formula,vardir = dir_fgt0_var, data = data3, method = "REML")
fh_model_FH <- eblupFH(formula,vardir = dir_fgt0_var, data = data3, method = "FH")
```


### Obtain SAE-FH estimates
```{r fh_model_final}
final_model <- eblupFH(formula,vardir = dir_fgt0_var, data = data3, method = "REML", PRECISION = 1e-13)
mse <- mseFH(formula,vardir = dir_fgt0_var, data = data3, method = "REML", PRECISION = 1e-13)
data4 <- data3 %>% mutate(
  fh_fgt0 = final_model$eblup,
  fh_fgt0_se = sqrt(mse$mse)
  ) 
```
## Check the normality of area effect and errors

### Calculate Area effect
```{r fh_model_area_effect}
data5 <- data4 %>% mutate(xb = predict(lm(formula, data = data4))) %>%
  mutate(u_d = fh_fgt0 - xb)
ggplot(data5, aes(x = u_d)) + geom_histogram(aes(y = ..density..),bins = 30, fill = "lightblue", color = "black") + stat_function(fun = dnorm, args = list(mean = mean(data5$u_d, na.rm=T), sd = sd(data5$u_d, na.rm=T)), color = "red")+
  ggtitle("Histogram of FH Area Effects") + theme_minimal()
```

### Draw the Q_Q plot for normality checks of FH area effects
```{r qqplot_area_effects}
ggplot(data5, aes(sample = u_d)) + stat_qq() + stat_qq_line(color = "red") + ggtitle("Q-Q Plot of FH Area Effects") + theme_minimal()
```

### Calcalate Errors
```{r fh_model_errors}
data5 <- data5 %>% mutate(e_d = dir_fgt0 - fh_fgt0)
ggplot(data5, aes(x = e_d)) + geom_histogram(aes(y = ..density..),bins = 30, fill = "lightblue", color = "black") + stat_function(fun = dnorm, args = list(mean = mean(data5$e_d, na.rm=T), sd = sd(data5$e_d, na.rm=T)), color = "red")+
  ggtitle("Histogram of FH Error") + theme_minimal()
```

### Q_Q plot for normality checks of errors
```{r qqplot_errors}
ggplot(data5, aes(sample = e_d)) + stat_qq() + stat_qq_line(color = "red") + ggtitle("Q-Q Plot of FH Error") + theme_minimal()
```
## Save the final data

### Save and output Final dataset
```{r save}
final_data <- data5 %>% select(region.y, district, fh_fgt0, fh_fgt0_se)
write_csv(final_data, "FH_sae_poverty.csv")
```
