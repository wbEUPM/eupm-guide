# Multivariate Fay–Herriot 

##	Stable FH estimators over T time periods
This section describes procedures that yield stable small area estimators for each of D areas over T subsequent time instants. 

MFH estimation procedure for T time instants:
Step 1 Compute the selected direct area estimators for each area d = 1, . . . , D for each time t = 1, . . . , T, 
and estimators of their corresponding sampling variances and covariances.

Step 2 Select the area-level auxiliary variables for each time instant in the MFH model. A simple approach is to perform a model selection procedure in a linear regression model without the area effects for each time instant t = 1, . . . , T .

Step 3 Fit MFH3 model and test whether the area-time effects (ud1, . . . , udT ) are homoscedastic or not. If we reject the homoscedasticity of variances, consider MFH3 model. Otherwise, consider MFH2 model.

Step 4 Check the selected model assumptions, including linearity, normality of pre- dicted area effects and standardized model residuals, and the presence of outlying areas.

Step 5 In case of clear systematic model departures, the model should be changed. In case of isolated departures because of outlying areas, either do not obtain the MFH estimate for those areas or change some aspect of the model or the data. Then, go to Step 2.

Step 6 If model assumptions hold, using the above direct estimates and estimated sampling variances and covariances, and the selected auxiliary variables, compute MFH estimators for, d = 1, . . . , D and t = 1, . . . , T , and their corresponding estimated MSEs.

The functions eblupMFH2() and eblupMFH3() from the R package msae (Per- matasari and Ubaidillah, 2022) compute the EBLUPs and their MSE estimates under the MFH models 2 and 3, respectively. The calls to these functions are:
$eblupMFH2(formula, vardir, MAXITER = 100, PRECISION = 1e-04, data)$ or $eblupMFH3(formula, vardir, MAXITER = 100, PRECISION = 1e-04, data)$.

The arguments of these two functions are the same, differing only in the outputs. They require specifying a list with T R formula objects, one for each time instant, separated by commas. In each of these regression formulas (one for each time instant), we place the vector of direct estimates on the left-hand side and the area-level independent variables on the right-hand side, separated by “+”. As usual, by default an intercept is automatically included in each regression formula.

As in the case of the eblupFH() function, they also require specifying the estimated sampling variances and covariances of the direct estimators for each area and time in the argument vardir. The user can also modify the maximum number of iterations, MAXITER, which is set by default to 100, and the convergence tolerance criteria, PRECISION, of the Fisher-scoring algorithm, which is set to 1e-4. The final argument, data, can be optionally specified to indicate a data object that includes the variables found in formula and vardir as its columns. Similar to the eblupFH() function, these functions do not accept NA values, and they will not return estimates for areas with zero sample sizes. Consequently, such areas should be excluded from the dataset.

Both functions return a list containing the following objects: eblup, a vector of EBLUPs for the areas; MSE, a data frame with the estimated mean squared errors of the EBLUPs; randomEffect, a data frame containing the predicted area-time effects; Rmatrix, a diagonal matrix with the sampling errors; and fit, a list with additional information from the model fitting. In the fit list, we can find the fitting method used (method); a logical value indicating the convergence of the Fisher scoring algorithm (convergence); the number of iterations performed by the Fisher scoring algorithm (iterations); a data frame containing the estimated regression coefficients in the first column, their standard errors in the second, the t statistics in the third, and the p-values of the significance of each coefficient in the last column (estcoef); a data frame with the estimated random effects variance (refvar); a data frame with the estimated autocorrelation coefficient ρ of the random effects; and the estimated Fisher information matrix (informationFisher).

The function eblupMFH3() additionally includes in the fit list, a contrast to test the homogeneity of random effects variance, called refvarTest. This test helps the user to choose between the heteroscedastic Model 3 or the homoscedastic Model 2, for a particular data set.

Example 1 below illustrates the calculation of MFH estimators of area poverty rates for T time instants, using the functions eblupMFH2() and eblupMFH3() of the R package msae (Permatasari and Ubaidillah, 2022).

### Example 1 (MFH estimators of poverty rates for T time periods, in R) 
In this example, we use the data set datasae3 from the R package msae (Permatasari and Ubaidillah, 2022). This data set contains simulated data generated under a FH model with heteroscedastic AR(1) area-time effects. There are two auxiliary variables, X1 and X2. Direct estimates for time instants 1,2 and 3 are given in Y1, Y2, and Y3, respectively. The elements of the variance-covariance matrix of the sampling errors are given in v1, v2, v3, v12, v13 and v23. 

We first load the package and the data set:

```{r load_data}
library(msae) 
data(datasae3)
```

Step 1: The direct area estimators and their sample variances are already given in the dataset.
Step 2: We should select the auxiliary variables at each time point. This example is only for illustration of application of the R function, and hence we use all the available variables, but we should emphasize the importance of this variable selection process in real-world applications.
Step 3: In order to choose between the two alternative MFH models with heteroscedastic or homoscedastic area-time effects, we fit the heteroscedastic Model 3, and then check for the equality of the variances over the three time points. Hence, we use the function eblupMFH3 to fit the model:

```{r run_mfh3}
Fo <- list(f1=Y1~X1+X2,
f2=Y2~X1+X2, f3=Y3~X1+X2)
vardir <- c("v1", "v2", "v3", "v12", "v13", "v23") 
m3 <- eblupMFH3(Fo, vardir, data=datasae3)
```

Next we check the equality of the random effect variances. For this, we use the results of a hypothesis test included in the output of the function eblupMFH3:
$m3$fit$refvarTest$.

This test tests the null hypothesis that the variances $σ^2$ at each pair of instants t and s are equal against the alternative that they are not. In this case, at significance level of 0.05, we reject the equality of variances between t = 3 and t = 1, as well as between t = 3 and t = 2. Note that this is a multiple test, and hence it is advisable to adjust the significance level. In this case, the tests clearly indicate heteroscedasticity, and we proceed with Model 3. If these tests supported equality of variances, then we would use instead the function eblupMFH2 for estimation.

Step 4: We now verify the assumptions of the MFH3 model. This includes assessing linearity, the normality of the predicted area effects and standardized residuals, as well as checking for the presence of outlying areas. We first check the linearity assumption. This can be addressed by examining the scatter plot of residuals against predicted values (EBLUPs). The plot is generated for each of the T = 3 time periods.

```{r figure1}
resids_3 <- cbind(datasae3$Y1-m3$eblup$Y1, datasae3$Y2-m3$eblup$Y2, datasae3$Y3-m3$eblup$Y3)
x11()
layout(matrix(1:3,nrow = 1, byrow = TRUE)) 
plot(m3$eblup$Y1,resids_3[,1],pch=19,xlab="EBLUPs t=1",ylab="Residuals t=1") 
plot(m3$eblup$Y2,resids_3[,2],pch=19,xlab="EBLUPs t=2",ylab="Residuals t=2") 
plot(m3$eblup$Y3,resids_3[,3],pch=19,xlab="EBLUPs t=3",ylab="Residuals t=3")
```

These three plots do not provide evidences against the linearity assumption. 
We now evaluate the normality assumption of residuals, again for the 3 time periods:
 
```{r figure2}
x11()
layout(matrix(1:2,nrow = 1, byrow = TRUE))
hist(resids_3[,1], probability=TRUE, main="",xlab="Residuals t=1", ylim=c(0,3.7))
mean_est <- mean(resids_3[,1]) sd_est <- sd(resids_3[,1])
curve(dnorm(x, mean=mean_est, sd=sd_est), add=TRUE, col="red", lwd=2) qqnorm(resids_3[,1], main="")
qqline(resids_3[,1], col="red") shapiro.test(resids_3[,1])
```

```{r figure3}
x11()
layout(matrix(1:2,nrow = 1, byrow = TRUE))
hist(resids_3[,2], probability=TRUE, main="",xlab="Residuals t=2") mean_est <- mean(resids_3[,2])
sd_est <- sd(resids_3[,2])
curve(dnorm(x, mean=mean_est, sd=sd_est), add=TRUE, col="red", lwd=2) qqnorm(resids_3[,2], main="")
qqline(resids_3[,2], col="red") shapiro.test(resids_3[,2])
```

```{r figure4}
x11()
layout(matrix(1:2,nrow = 1, byrow = TRUE))
hist(resids_3[,3], probability=TRUE, main="",xlab="Residuals t=3") mean_est <- mean(resids_3[,3])
sd_est <- sd(resids_3[,3])
curve(dnorm(x, mean=mean_est, sd=sd_est), add=TRUE, col="red", lwd=2) qqnorm(resids_3[,3], main="")
qqline(resids_3[,3], col="red") shapiro.test(resids_3[,3])
``` 

In this case, the above histograms and Q-Q normal plots, as well as the Shapiro-Wilk tests, indicate nothing against the normality assumption of residuals. We next evaluate the normality of the random effects. Luckily, the function eblupMFH3 provides the random effects in its output, for the three time periods:
```{r figure5}
ran_eff <- m3$randomEffect 
x11()
layout(matrix(1:2,nrow = 1, byrow = TRUE))
hist(ran_eff$Y1, probability=TRUE, main="",xlab="Random Effects", ylim = c(0,0.45))
mean_est <- mean(ran_eff$Y1) sd_est <- sd(ran_eff$Y1)
curve(dnorm(x, mean=mean_est, sd=sd_est), add=TRUE, col="red", lwd=2) qqnorm(ran_eff$Y1, main="")
qqline(ran_eff$Y1, col="red") shapiro.test(ran_eff$Y1)
```

```{r figure6}
x11()
layout(matrix(1:2,nrow = 1, byrow = TRUE)) hist(ran_eff$Y2,probability=TRUE,main="",xlab="Random Effects",breaks=5) mean_est <- mean(ran_eff$Y2)
sd_est <- sd(ran_eff$Y2)
curve(dnorm(x, mean=mean_est, sd=sd_est), add=TRUE, col="red", lwd=2) qqnorm(ran_eff$Y2, main="")
qqline(ran_eff$Y2, col="red") shapiro.test(ran_eff$Y2)
 ```

```{r figure7}
x11()
layout(matrix(1:2,nrow = 1, byrow = TRUE))
hist(ran_eff$Y3, probability=TRUE, main="",xlab="Random Effects") mean_est <- mean(ran_eff$Y3)
sd_est <- sd(ran_eff$Y3)
curve(dnorm(x, mean=mean_est, sd=sd_est), add=TRUE, col="red", lwd=2) qqnorm(ran_eff$Y3, main="")
qqline(ran_eff$Y3, col="red") shapiro.test(ran_eff$Y3)
```

Again, histograms and Q-Q normal plots show no evidences of departure from normality, while the Shapiro-Wilk test also supports normality for all time periods at the usual significance level of 0.05, except for t = 2, which is supported at 0.01 level.

Step 5: Since no indications are found against the MFH3 model assumptions, we proceed to obtain the small area estimates, as well as their estimated MSEs. These are already been generated at output of the function together with the model fit, and can be printed as follows.
$m2$eblup$	# To see the EBLUPs
$m2$MSE$	# To see estimated MSEs of EBLUPs

We next illustrate the use of the function eblupMFH2, which should be used in the case of homoscedastic area-time effects over time. For this, we employ datasae2 from the R package msae (Permatasari and Ubaidillah, 2022). In this new data set, again X1 and X2 are the auxiliary variables, and Y1, Y2, and Y3 are the direct estimates at times 1, 2, and 3, respectively. The elements of the variance-covariance matrix of the sampling errors are provided in the variables v1, v2, v3, v12, v13, and v23. Again, we first load the package and the data set:

```{r load_data2}
library(msae) 
data(datasae2)
```

We now fit model MFH2 and check the model assumptions:

```{r run_mfh2}
Fo <- list(f1=Y1~X1+X2,
f2=Y2~X1+X2, f3=Y3~X1+X2)
vardir <- c("v1", "v2", "v3", "v12", "v13", "v23") m2 <- eblupMFH2(Fo, vardir, data=datasae2) m2$eblup	# To see the EBLUPs
m2$MSE	# To see the estimated MSEs of EBLUPs
```

##	Spatio-temporal FH estimators over T time periods
This section describes an extension of the FH model by Marhuenda et al. (2013), which incorporates spatial correlation between neighboring areas and temporal correlation over T time instants, leading to more stable small area estimates over time.

STFH estimation procedure for T time instants:
Step 1 Compute the selected direct area estimators for each area, d = 1, . . . , D, and for each time t = 1, . . . , T ,
and estimators of their corresponding sampling variances.

Step 2 Select the area-level auxiliary variables for each time instant in the STFH model. A simple approach is to perform a model selection procedure in a linear regression model without the area effects for each time instant t = 1, . . . , T .

Step 3 Fit the STFH model and check the model assumptions, including linearity, normality of predicted area effects and standardized model residuals, and the presence of outlying areas, for each time instant T .

Step 4 In case of clear systematic model departures, the model should be changed. In case of isolated departures because of outlying areas, either do not obtain the STFH estimate for those areas or change some aspect of the model or the data. Then, go to Step 2.

Step 5 If model assumptions hold, using the above direct estimates, their estimated sampling variances, and the selected auxiliary variables, compute STFH estimators for each area d = 1, . . . , D and each time t = 1, . . . , T , and their corresponding estimated MSEs.

EBLUPs for all areas and time instants, and parametric bootstrap MSE estimates can be obtained calling functions eblupSTFH() and pbmseSTFH() respectively. 
The calls to these functions are:
$eblupSTFH(formula, D, T, vardir, proxmat, model = "ST", MAXITER =100, PRECISION = 0.0001, data)$
$pbmseSTFH(formula, D, T, vardir, proxmat, B = 100, model = "ST", MAXITER = 100, PRECISION = 0.0001, data)$
 
Some of the arguments are exactly the same as in the functions for FH model described in Section 4. Among the additional arguments, we have the number of areas D and the number of time periods T for each area. We remark that these functions may be used only when data are available for all the D domains at all T time periods. Moreover, data in formula and vardir must be sorted in ascending order by time instant, for each domain. Note that a single formula is specified in this function, unlike in the functions for the MFH modes of Section 5. The argument model can be chosen between the default value ST (AR(1) time-effects within each domain) or value S (with uncorrelated time effects within each domain). The rwo-standardized proximity matrix, W, must be also given as input in proxmat. The elements of this matrix are in [0,1], zeros on the diagonal and rows adding up to 1, as described above.

The function pbmseSTFH() providing bootstrap MSE estimates requires additionally to specify the number of bootstrap replicates B. A number of bootstrap replicates B ≥ 400 is advisable to achieve stable MSE estimates. By default, the argument B is set to 100 to save computing time. To obtain the same MSE estimates every time the function pbmseSTFH() is run, the seed for random number generation should be fixed previously using set.seed(). 

Example 2 illustrates the calculation of STFH estimators of area poverty rates for T time instants, using the above functions.

### Example 4 (Spatio-temporal FH estimators of poverty rates, in R) 
In this example, we use the data set spacetime included in the R package sae, which contains synthetic area level data for T = 3 time points, for each of D = 11 areas. The data set contains the following variables: Area, area code, Time, time point, X1 and X2, the auxiliary variables for each area and time instant, Y2, direct estimates for each area and time instant, and Var, sampling variances of the direct estimators. We calculate EBLUPs of the means for each area at each time, based on the STFH model with prox- imity matrix given in the data set spacetimeprox. We also obtain the corresponding MSE estimates by parametric bootstrap. The steps of the STFH procedure described above should be followed but, in this example, we only illustrate the calculation of the small area estimators and their estimated MSEs. 

We first load the two data sets and obtain the number of areas and of time instants. Then, we apply the function pbmseSTFH() that delivers both, the STFH estimates and their estimated MSEs:

```{r run_STFH}
data("spacetime") 
data("spacetimeprox")
D <- nrow(spacetimeprox)	# number of areas
T <- length(unique(spacetime$Time))	# number of time periods set.seed(123)
STFH <- pbmseSTFH(Y ~ X1 + X2, D, T, vardir = Var, spacetimeprox, data = spacetime)
```

The bootstrap procedure for MSE estimation displays the iteration number for each step, as follows:
Bootstrap procedure with B = 100 iterations starts. 
Once we have obtained the STFH estimators, we compute their CVs, and the same is done for the direct estimators. We print the results for the last time instant (T = 3):
 
```{r cv_STFH}
cv.STFH <- 100 * sqrt(STFH$mse) / STFH$est$eblup cv.DIR <- 100 * sqrt(spacetime$Var) / spacetime$Y
results <- data.frame(Area = spacetime$Area, Time = spacetime$Time,
DIR = spacetime$Y, eblup.STFH = STFH$est$eblup, cv.DIR, cv.STFH)
results.lasttime <- results[results$Time == 3, ] print(results.lasttime, row.names = FALSE)
```

Next we plot the STFH and the direct estimates together for comparison. Additionally, we plot their corresponding CVs. 
The following R code generates both plots:

```{r figure8}
x11()
layout(1)
results.lasttime <- results.lasttime[order(results.lasttime$cv.DIR), ] plot(results.lasttime$DIR, type = "n", xlab = "area (time=3)",
ylab = "Estimate",ylim = c(0.05, 0.45), cex.axis = 1.5, cex.lab = 1.5, xaxt = "n")
axis(1, 1:11, results.lasttime$Area, cex.axis = 1.5) points(results.lasttime$DIR, type = "b", col = 1, lwd = 2, pch = 1) points(results.lasttime$eblup.STFH, type = "b", col = 4,lwd = 2,pch = 4) legend("top", legend = c("Direct", "EBLUP STFH"), ncol = 2, col = c(1, 4), lwd = rep(2, 2), pch = c(1, 4), cex = 1.3)
plot(results.lasttime$cv.DIR, type = "n", xlab = "area (time=3)", ylab="CV",cex.axis = 1.5, cex.lab = 1.5, xaxt = "n")
axis(1, 1:11, results.lasttime$Area, cex.axis = 1.5) 
points(results.lasttime$cv.DIR, type = "b", col = 1, lwd = 2, pch = 1) 
points(results.lasttime$cv.STFH, type = "b", col = 4, lwd = 2, pch = 4) 
legend("top", legend = c("Direct", "EBLUP STFH"), ncol = 2, col=c(1,4), lwd = rep(2, 2), pch = c(1, 4), cex = 1.3)
```

The left figure shows the STFH estimators, together with the direct estimates for each area at the last time point, with areas sorted by increasing CVs of direct estimators. The right figure shows the corresponding CVs. In this example, we can see that, even with a very small number of areas (D = 11) and time instants (T = 3) to borrow strength from, the STFH estimates follow closely direct estimates, but are slightly more stable than them, and have smaller estimated CVs for all the areas.

We also apply basic univariate FH models for each time instant, that is, cross- sectionally, to analyze the differences with the results obtained from the STFH model.
For this, we first select the data corresponding to each time instant and then call the function mseFH() using those separate data sets. STFH estimates are stored in an additional column of the data frame results:

```{r figure8}
data.time1<-spacetime[spacetime$Time==1,] 
data.time2<-spacetime[spacetime$Time==2,] data.time3<-spacetime[spacetime$Time==3,]
eblup.FH.res.time1<-mseFH(Y~X1+X2,vardir=Var,data=data.time1) 
eblup.FH.time1<-eblup.FH.res.time1$est$eblup 
results$eblup.FH[results$Time==1]<-eblup.FH.time1
eblup.FH.res.time2<-mseFH(Y~X1+X2,vardir=Var,data=data.time2) 
eblup.FH.time2<-eblup.FH.res.time2$est$eblup r
esults$eblup.FH[results$Time==2]<-eblup.FH.time2
eblup.FH.res.time3<-mseFH(Y~X1+X2,vardir=Var,data=data.time3) 
eblup.FH.time3<-eblup.FH.res.time3$est$eblup r
results$eblup.FH[results$Time==3]<-eblup.FH.time3
```
Let us now plot the STFH estimates, together with direct and cross-sectional FH estimates, for the first area (coded as Area=2) over the three time instants:
results.A1 <- results[results$Area == 2, ]

x11()
layout(1) k<-3
m<-min(results.A1$DIR,results.A1$eblup.STFH,results.A1$eblup.FH) M<-max(results.A1$DIR,results.A1$eblup.STFH,results.A1$eblup.FH) plot(1:3,results.A1$DIR, type = "n", xlab = "Time",
ylab = "Estimates: First area", ylim = c(m,M+(M-m)/k), cex.axis = 1.5, cex.lab = 1.5, xaxt = "n")
 

axis(1, 1:3, 1:3, cex.axis = 1.5)
points(1:3,results.A1$DIR, type = "b", col = 1, lwd = 2, pch = 1) points(1:3,results.A1$eblup.FH, type = "b", col = 3,lwd = 2,pch = 3) points(1:3,results.A1$eblup.STFH, type = "b", col = 4,lwd = 2,pch = 4) legend("top", legend = c("Direct", "EBLUP FH", "EBLUP STFH"), ncol = 2,
col = c(1,3,4),lwd = rep(2,3), pch = c(1,3,4), cex = 1.3)
Finally, we repeat the process for the last area (coded as Area=46): results.A11 <- results[results$Area == 46, ]
x11()
layout(1) k<-3
m<-min(results.A11$DIR,results.A11$eblup.STFH,results.A11$eblup.FH) M<-max(results.A11$DIR,results.A11$eblup.STFH,results.A11$eblup.FH) plot(1:3,results.A11$DIR, type = "n", xlab = "Time",
ylab = "Estimates: Last area", ylim = c(m, M+(M-m)/k), cex.axis = 1.5, cex.lab = 1.5, xaxt = "n")
axis(1, 1:3, 1:3, cex.axis = 1.5)
points(1:3,results.A11$DIR, type = "b", col = 1, lwd = 2, pch = 1) points(1:3,results.A11$eblup.FH, type = "b", col = 3,lwd = 2,pch = 3) points(1:3,results.A11$eblup.STFH, type = "b", col = 4,lwd = 2,pch = 4) legend("top", legend = c("Direct", "EBLUP FH", "EBLUP STFH"), ncol = 2,
col = c(1,3,4), lwd = rep(2,3), pch = c(1,3,4), cex = 1.3)
Results are shown in Figure 14. We did already see in the previous examples that direct estimators are unstable across areas. We can see that they are also the most unstable over time. Cross-sectional FH estimators applied for each time instant t = 1, 2, 3, are more stable across areas, but not necessarily over time. Figure 14 shows that STFH estimators are smoother over time than both, direct and cross-sectional FH estimates.



 	 
 
1	2	3
Time
 
1	2	3
Time
 

Figure 14: Direct, FH and STFH estimates of the area means for the first area (left) and the last area (right).
 
7	Statistical comparison of indicators over time
Now consider that, for a given area d, we wish to compare the indicators at two time periods, δdt and δds, with s < t; more concretely, we wish to analyze the increment
∆d = δdt − δds. Let δˆEB and δˆEB be EB predictors of δdt and δds obtained either from
dt	ds
the MFH of Section 5 or the STFH model of Section 6. Since there is dependency, making inference to compare δdt and δds entails accounting for the uncertainty of the difference of EB predictors ∆ˆ EB = δˆEB − δˆEB , which is given by
d	dt	ds
MSE(∆ˆ EB ) = MSE(δˆEB ) + MSE(δˆEB ) − 2 MCPE(δˆEB , δˆEB ).
d	dt	ds	ds	dt
Then, apart from estimators M^SE(δˆEB ) and M^SE(δˆEB ) of MSE(δˆEB ) and MSE(δˆEB ),
dt	ds	dt	ds
an estimator M^CPE(δˆEB , δˆEB ) of MCPE(δˆEB , δˆEB ) is required. Then, an estimator
dt	ds	dt	ds
of the MSE of the difference is given by
M^SE(∆ˆ EB ) = M^SE(δˆEB ) + M^SE(δˆEB ) − 2 M^CPE(δˆEB , δˆEB ).
d	dt	ds	ds	dt
Although the distribution of the EB predictors is not really normal, a simple approximate 1 − α confidence interval for the increment ∆d, can be obtained using the normal quantile, as
CIα(∆d) = ∆ˆ EB ∓ Zα/2ñM^SE(∆ˆ EB ).
Using this interval, we can say that the difference ∆d between indicators at times t and s is statistically different from zero at level α, if the 1 − α confidence interval does not contain zero. Other hypotheses can also be tested about the increment ∆d. Instead of considering the normal quantiles, an alternative approach is to use a bootstrap confidence interval.
The R package msae by Permatasari and Ubaidillah (2022) used in Section 5 and the functions for the STFH model of the R package sae by Molina and Marhuenda (2009)
deliver the EBLUPs δˆEB of δdt, and their estimated MSEs, M^SE(δˆEB ), d = 1, . . . , D,
dt	dt
for each time point t = 1, . . . , T . Unluckily, these functions do not return estimates of the MCPE of two EB predictors. Again, a bootstrap procedure may be employed to estimate the MCPE and at the same time obtaining a confidence interval for ∆d or performing a hypothesis test about ∆d. Development and implementation of this bootstrap methodology would be needed.




